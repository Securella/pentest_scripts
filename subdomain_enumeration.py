import os
import sys
import requests
from concurrent.futures import ThreadPoolExecutor
from requests.exceptions import Timeout
from tabulate import tabulate  # tabulate for table output

# This script reads a wordlist file specified as the first argument
# (sys.argv[1]) and constructs URLs by appending each subdomain
# from the wordlist to the domain specified as the second argument
# (sys.argv[2]).
# It then attempts to make a GET request to each URL and prints 
# the valid domains if the request is successful.

# + script utilizes multithreading and timeout handling (better performance).


def check_subdomain(sub_domain):
    url = f"http://{sub_domain}.{sys.argv[2]}"
    try:
        response = requests.get(url, timeout=5)  # timeout of 5 seconds to the request
        if response.ok:
            return sub_domain, response.status_code  # Return subdomain + status code
    except (requests.ConnectionError, Timeout):
        pass
    return None


def main():
    # Original comment: Check if the correct number of arguments are provided
    if len(sys.argv) != 3:
        print("Usage: python3 subdomain_enumeration.py <path_to_wordlist> <domain>")
        return

    file_path = os.path.join(os.getcwd(), sys.argv[1])  # Construct the full path to the wordlist file

    with open(file_path) as file:  # Original comment: Read the wordlist file
        subdoms = file.read().splitlines()

    results = []  # Initialize results list

    with ThreadPoolExecutor(max_workers=10) as executor:  # Utilize ThreadPoolExecutor for concurrent subdomain checks
        for result in executor.map(check_subdomain, subdoms):
            if result:
                results.append(["Valid domain:", f"http://{result[0]}", "Status code:", result[1]])  # Append formatted result to results list

    # Print the table
    print(tabulate(results, tablefmt="grid"))


if __name__ == "__main__":
    main()

