# source for the base code: https://medium.com/@cn.cyber/advanced-python-scripting-for-penetration-testers-boosting-your-arsenal-509879d95fcb
# now script only looks for emails indicated on the page and in the page source
import sys
import re
import csv
from selenium import webdriver
from urllib.error import HTTPError
from bs4 import BeautifulSoup


def scrape_emails_from_url(url, output_file):
    try:
        # Initialize Chrome WebDriver
        # Make sure to have Chrome WebDriver installed!
        driver = webdriver.Chrome()
        driver.get(url)

        # Print the title of the webpage
        print("Scraping using Selenium:")
        print("Title:", driver.title)

        # Extract from webpage directly
        emails_onpage = extract_emails_from_page(driver.page_source)
        print_emails("Emails found directly on page:", emails_onpage)

        # Extract emails from the entire page source
        emails_pagesource = extract_emails_from_page_source(driver.page_source)
        print_emails("Emails found in page source:", emails_pagesource)

        # Write emails to CSV file
        write_emails_to_csv(emails_onpage, emails_pagesource, output_file)

    except HTTPError as e:
        if e.code == 403:
            print("403 Forbidden Error: Access denied.")
        else:
            print("HTTP Error:", e.code)
    except Exception as e:
        print("An error occurred:", e)
    finally:
        # Close the WebDriver instance
        driver.quit()


def extract_emails_from_page(page_source):
    # Use BeautifulSoup to parse the HTML and extract emails from visible content
    soup = BeautifulSoup(page_source, 'html.parser')
    visible_emails = set()
    for email in soup.find_all(text=re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')):
        visible_emails.add(email.strip())
    return visible_emails


def extract_emails_from_page_source(page_source):
    # Extract emails from the entire page source using regular expressions
    return set(re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', page_source))


def print_emails(message, emails):
    if emails:
        print(message)
        for email in emails:
            print(email)
    else:
        print("No emails found.")


def write_emails_to_csv(emails_onpage, emails_pagesource, output_file):
    with open(output_file, 'w', newline='') as csvfile:
        fieldnames = ['Type', 'Email']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

        writer.writeheader()
        if emails_onpage:
            for email in emails_onpage:
                writer.writerow({'Type': 'On Page', 'Email': email})
        if emails_pagesource:
            for email in emails_pagesource:
                writer.writerow({'Type': 'Page Source', 'Email': email})


if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: python3 web_scraper.py <url> <output_file.csv> OR python web_scraper.py <url> <output_file.csv>")
        sys.exit(1)
    url = sys.argv[1]
    output_file = sys.argv[2]
    scrape_emails_from_url(url, output_file)
